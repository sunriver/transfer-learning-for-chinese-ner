{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:34:43.219901Z",
     "start_time": "2019-10-31T07:34:43.207038Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path: \n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils as myutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:34:51.984953Z",
     "start_time": "2019-10-31T07:34:45.119601Z"
    }
   },
   "outputs": [],
   "source": [
    "normal_train, normal_test = myutils.get_sentence(\"../data/train\", \"../data/test\")\n",
    "# data_test = myutils.get_sentence(\"../data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:27:55.521266Z",
     "start_time": "2019-10-31T02:27:55.510639Z"
    }
   },
   "outputs": [],
   "source": [
    "# display(normal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:34:56.102952Z",
     "start_time": "2019-10-31T07:34:54.321149Z"
    }
   },
   "outputs": [],
   "source": [
    "transfer_train, transfer_test = myutils.get_sentence(\"../data/transfer_train\", \"../data/transfer_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:34:58.927155Z",
     "start_time": "2019-10-31T07:34:58.917006Z"
    }
   },
   "outputs": [],
   "source": [
    "char2id, id2char, tag2id, id2tag, transfer_tag2id, transfer_id2tag = myutils.get_transform(normal_train + transfer_train, \n",
    "                                                                                       \"../data/maps.pkl\",\n",
    "                                                                                       \"../data/tag2label.json\",\n",
    "                                                                                       \"../data/transfer_tag2label.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:35:01.782864Z",
     "start_time": "2019-10-31T07:35:01.770681Z"
    }
   },
   "outputs": [],
   "source": [
    "#字符index 从1开始，这样pad_sequence是默认填充值为0不会冲突，设置embed，mask_zero==True，请参考https://blog.csdn.net/songbinxu/article/details/80150019\n",
    "char2id = dict((v, i+1) for v, i in char2id.items()) \n",
    "# id2char = dict((i+1, v)for i, v in id2char.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:27:57.063331Z",
     "start_time": "2019-10-31T02:27:57.060056Z"
    }
   },
   "outputs": [],
   "source": [
    "# id2char = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:27:57.067995Z",
     "start_time": "2019-10-31T02:27:57.065431Z"
    }
   },
   "outputs": [],
   "source": [
    "# display(char2id)\n",
    "# print(char2id.get(\"<UNK>\"))\n",
    "# len(char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:27:57.073690Z",
     "start_time": "2019-10-31T02:27:57.070212Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data = myutils.preprocess_data(normal_train, char2id, tag2id)\n",
    "# test_data = myutils.preprocess_data(normal_test, char2id, tag2id)\n",
    "# transfer_train_data = myutils.preprocess_data(transfer_train, char2id, transfer_tag2id)\n",
    "# transfer_test_data = myutils.preprocess_data(transfer_test, char2id, transfer_tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T05:49:54.148744Z",
     "start_time": "2019-10-25T05:49:54.144814Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:35:04.825735Z",
     "start_time": "2019-10-31T07:35:04.816411Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "doc_maxlen = 30\n",
    "UNKNOWN_CHAR = myutils.UNKNOWN_CHAR\n",
    "def preprocess_data(sentences, char2id, tag2id):\n",
    "  char_ids = [[char2id[char[0] if char[0] in char2id else UNKNOWN_CHAR] for char in sentence] for sentence in sentences]\n",
    "  tag_ids = [[tag2id[char[1]] for char in sentence ] for sentence in sentences]\n",
    "   \n",
    "  char_ids = pad_sequences(char_ids, doc_maxlen)\n",
    "  tag_ids = pad_sequences(tag_ids, doc_maxlen, value=-1)\n",
    "  tag_ids = np.expand_dims(tag_ids, 2) #扩展维度 对应sparse_target = True\n",
    "  return char_ids, tag_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:35:09.377984Z",
     "start_time": "2019-10-31T07:35:07.761939Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X, train_y = preprocess_data(normal_train, char2id, tag2id)\n",
    "test_X, test_y = preprocess_data(normal_test, char2id, tag2id)\n",
    "transfer_train_X, transfer_train_y = preprocess_data(transfer_train, char2id, transfer_tag2id)\n",
    "transfer_test_X, transfer_test_y = preprocess_data(transfer_test, char2id, transfer_tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:27:59.171910Z",
     "start_time": "2019-10-31T02:27:59.166601Z"
    }
   },
   "outputs": [],
   "source": [
    "# display(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:35:12.398237Z",
     "start_time": "2019-10-31T07:35:12.359434Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras_contrib.losses import crf_loss\n",
    "# from keras_contrib.layers import crf\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:35:15.400120Z",
     "start_time": "2019-10-31T07:35:15.377521Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_words_maxlen = doc_maxlen\n",
    "embed_output_dim = 50\n",
    "tags_num = len(tag2id)\n",
    "transfer_tags_num = len(transfer_tag2id)\n",
    "embed_mask_zero = True\n",
    "vocab_size = len(char2id) if not embed_mask_zero else len(char2id) + 1\n",
    "\n",
    "def create_normal_model(tags_num):\n",
    "    layer_input_char = Input(shape=(doc_words_maxlen, ), name = \"input_char\")\n",
    "    print(layer_input_char.name, layer_input_char.shape)\n",
    "    layer_embed_char = Embedding(input_dim=vocab_size, output_dim=embed_output_dim, name=\"embed_char\", mask_zero=embed_mask_zero)(layer_input_char)\n",
    "    print(layer_embed_char.name, layer_embed_char.shape)\n",
    "    layer_bilstm = Bidirectional(LSTM(units=10, return_sequences = True), name=\"bilstm\")(layer_embed_char)\n",
    "    print(layer_bilstm.name, layer_bilstm.shape)\n",
    "    # sparse_target=true值label为数字，请参考https://github.com/keras-team/keras-contrib/issues/179\n",
    "    layer_crf = CRF(tags_num, sparse_target=True, name = \"out_crf\")(layer_bilstm)\n",
    "    print(layer_crf.name, layer_crf.shape)\n",
    "    \n",
    "    model = Model(inputs = layer_input_char, outputs=[layer_crf])\n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss = crf_loss,\n",
    "                  metrics= [crf_accuracy]\n",
    "                 )\n",
    "    return model\n",
    "    \n",
    "def create_normal_and_transfer_models(normal_tags_num, transfer_tags_num):\n",
    "    layer_input_char = Input(shape=(doc_words_maxlen, ), name = \"input_char\")\n",
    "    print(layer_input_char.name, layer_input_char.shape)\n",
    "    layer_embed_char = Embedding(input_dim=vocab_size, output_dim=embed_output_dim, name=\"embed_char\", mask_zero=embed_mask_zero)(layer_input_char)\n",
    "    print(layer_embed_char.name, layer_embed_char.shape)\n",
    "    layer_bilstm = Bidirectional(LSTM(units=10, return_sequences = True), name=\"bilstm\")(layer_embed_char)\n",
    "    print(layer_bilstm.name, layer_bilstm.shape)\n",
    "    layer_crf_normal = CRF(tags_num, sparse_target=True, name = \"out_crf_normal\")(layer_bilstm)\n",
    "    layer_crf_transfer = CRF(transfer_tags_num, sparse_target=True, name = \"out_crf_transfer\")(layer_bilstm)\n",
    "    \n",
    "    normal_model = Model(inputs = layer_input_char, outputs=[layer_crf_normal])\n",
    "    transfer_model = Model(inputs = layer_input_char, outputs =[layer_crf_transfer])\n",
    "    normal_model.compile(optimizer=\"adam\", \n",
    "                  loss = crf_loss,\n",
    "                  metrics= [crf_accuracy]\n",
    "                 )\n",
    "    transfer_model.compile(optimizer=\"adam\", \n",
    "                  loss = crf_loss,\n",
    "                  metrics= [crf_accuracy]\n",
    "                 )\n",
    "    return normal_model, transfer_model\n",
    "\n",
    "\n",
    "def create_mulittask_model():\n",
    "#     layer_input_word = Input(shape=(doc_words_maxlen,), name=\"input_word\")\n",
    "#     layer_embed_word = Embedding(input_dim=vocab_size, output_dim=embed_output_dim, name=\"embed_word\")(layer_input_word)\n",
    "    layer_input_char = Input(shape=(doc_words_maxlen, ), name = \"input_char\")\n",
    "    print(layer_input_char.name, layer_input_char.shape)\n",
    "    layer_embed_char = Embedding(input_dim=vocab_size, output_dim=embed_output_dim, name=\"embed_char\")(layer_input_char)\n",
    "    print(layer_embed_char.name, layer_embed_char.shape)\n",
    "    layer_bilstm = Bidirectional(LSTM(units=20, return_sequences = True))(layer_embed_char)\n",
    "    print(layer_bilstm.name, layer_bilstm.shape)\n",
    "    layer_crf1 = CRF(units=crf1_tags_num, sparse_target=True, name = \"out_crf1\")(layer_bilstm)\n",
    "    print(layer_crf1.name, layer_crf1.shape)\n",
    "    layer_crf2 = CRF(units=crf2_tags_num, name = \"out_crf2\")(layer_bilstm)\n",
    "    \n",
    "    model = Model(inputs = layer_input_char, outputs=[layer_crf1, layer_crf2])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss={\"out_crf1\" : \"categorical_crossentropy\", \"out_crf2\" : \"categorical_crossentropy\"},\n",
    "                  loss_weights={\"out_crf1\": 1, \"out_crf2\" : 1},\n",
    "                  metrics={\"out_crf1\" : \"categorical_accuracy\", \"out_crf2\" : \"categorical_accuracy\"}\n",
    "\n",
    "                 )\n",
    "    return model\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:21:11.509625Z",
     "start_time": "2019-10-31T07:21:11.503699Z"
    }
   },
   "outputs": [],
   "source": [
    "# def test_normal_model(normal_model):\n",
    "#     normal_model.fit(train_X, train_y,\n",
    "#                 epochs=1,\n",
    "#                 validation_data=(\n",
    "#                     test_X,\n",
    "#                     test_y\n",
    "#                 ),\n",
    "#                 verbose=1)\n",
    "#     normal_model.trainable = False\n",
    "#     normal_model.compile(optimizer=\"adam\", \n",
    "#                   loss = crf_loss,\n",
    "#                   metrics= [crf_accuracy]\n",
    "#                  )  \n",
    "#     normal_model.save(\"normal_model_trained.h5\")\n",
    "\n",
    "# def test_transfer_model(transfer_model):\n",
    "#     transfer_model.save(\"transer_model.h5\")\n",
    "#     pass\n",
    "    \n",
    "                \n",
    "                  \n",
    "# test_normal_and_transfer_modes()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:35:20.288614Z",
     "start_time": "2019-10-31T07:35:18.409269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_char:0 (?, 30)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "embed_char/embedding_lookup/Identity:0 (?, 30, 50)\n",
      "bilstm/concat:0 (?, ?, 20)\n",
      "out_crf/cond/Merge:0 (?, ?, 7)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_char (InputLayer)      (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embed_char (Embedding)       (None, 30, 50)            253700    \n",
      "_________________________________________________________________\n",
      "bilstm (Bidirectional)       (None, 30, 20)            4880      \n",
      "_________________________________________________________________\n",
      "out_crf (CRF)                (None, 30, 7)             210       \n",
      "=================================================================\n",
      "Total params: 258,790\n",
      "Trainable params: 258,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "normal_model = create_normal_model(tags_num)    \n",
    "normal_model.summary()  \n",
    "normal_model.save(\"normal_model.h5\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:36:33.417976Z",
     "start_time": "2019-10-31T07:35:23.333431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50658 samples, validate on 4631 samples\n",
      "Epoch 1/1\n",
      "50658/50658 [==============================] - 68s 1ms/step - loss: 0.5789 - crf_accuracy: 0.9143 - val_loss: 1.5374 - val_crf_accuracy: 0.9488\n"
     ]
    }
   ],
   "source": [
    "normal_model.fit(train_X, train_y,\n",
    "                epochs=1,\n",
    "                validation_data=(\n",
    "                    test_X,\n",
    "                    test_y\n",
    "                ),\n",
    "                verbose=1)\n",
    "\n",
    "normal_model.save(\"normal_model_trained.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:30:05.045833Z",
     "start_time": "2019-10-31T02:30:05.036394Z"
    }
   },
   "outputs": [],
   "source": [
    "# normal_model.fit(x=train, \n",
    "#           y={\"out_crf1\" : [],  \"out_crf2\" :[]},\n",
    "#           validation_data = (\n",
    "#               test, \n",
    "#               {\"out_crf1\" : [],  \"out_crf2\" :[]}\n",
    "#           ),\n",
    "#           epochs= 5,\n",
    "#           verbose=1,\n",
    "#           batch_size=64 \n",
    "#          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:36:42.829246Z",
     "start_time": "2019-10-31T07:36:41.079360Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_y = normal_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:30:08.674056Z",
     "start_time": "2019-10-31T02:30:08.666483Z"
    }
   },
   "outputs": [],
   "source": [
    "# display(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:36:46.019704Z",
     "start_time": "2019-10-31T07:36:45.763067Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_y.shape\n",
    "# pred_y_results=[]\n",
    "pred_y_results = [[np.argmax(pred_y[i][j]) for j in range(pred_y.shape[1])] for i in range(pred_y.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:36:50.482210Z",
     "start_time": "2019-10-31T07:36:50.478803Z"
    }
   },
   "outputs": [],
   "source": [
    "# true_y_results = [[np.argmax(test_y[i][j]) for j in range(test_y.shape[1])] for i in range(test_y.shape[0])]\n",
    "true_y_results = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:36:53.573937Z",
     "start_time": "2019-10-31T07:36:53.569328Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_y_results = np.array(pred_y_results)\n",
    "true_y_results = np.array(true_y_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:36:56.334453Z",
     "start_time": "2019-10-31T07:36:56.329873Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_y_results = pred_y_results.reshape(-1, )\n",
    "true_y_results = true_y_results.reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T06:30:41.592465Z",
     "start_time": "2019-10-31T06:30:41.578529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(np.max(pred_y_results))\n",
    "# print(true_y_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:30:08.966230Z",
     "start_time": "2019-10-31T02:30:08.960221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-LOC': 3,\n",
       " 'I-LOC': 4,\n",
       " 'B-ORG': 5,\n",
       " 'I-ORG': 6}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:37:10.841455Z",
     "start_time": "2019-10-31T07:37:10.837248Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:30:08.977824Z",
     "start_time": "2019-10-31T02:30:08.974367Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# TagScore = namedtuple(\"TagScore\", [\"tag\", \"id\", \"count_tp\", \"count_true\", \"count_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T02:30:08.985320Z",
     "start_time": "2019-10-31T02:30:08.980227Z"
    }
   },
   "outputs": [],
   "source": [
    "# s1 = TagScore(\"tag\", 11, tp=0, fp=0, precision=0.0, recall=0.0, f1=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:37:15.822687Z",
     "start_time": "2019-10-31T07:37:14.964811Z"
    }
   },
   "outputs": [],
   "source": [
    "def caculate_precision_recall_f1(tag2id, id2tag, pred_ids, true_ids):\n",
    "    scores = {}\n",
    "    for tag, ID in tag2id.items():\n",
    "      scores[ID] = {\"tag\" : tag,\n",
    "                    \"id\" : ID,\n",
    "                    \"count_tp\" : 0,\n",
    "                    \"count_true\" : 0,\n",
    "                    \"count_pred\" : 0\n",
    "                   }\n",
    "    for i in range(len(pred_ids)):\n",
    "        ID = pred_ids[i]\n",
    "        if ID < 0:\n",
    "            continue\n",
    "        scores[ID][\"count_pred\"] += 1\n",
    "        \n",
    "    for i in range(len(true_ids)):\n",
    "        ID = true_ids[i]\n",
    "        if ID < 0:\n",
    "            continue\n",
    "        scores[ID][\"count_true\"] += 1\n",
    "        if pred_ids[i] == true_ids[i]:\n",
    "            scores[ID][\"count_tp\"] += 1       \n",
    "    \n",
    "#     for tag, ID in tag2id.items():\n",
    "#         for i in range(len(pred_ids)):\n",
    "#             pred_id = pred_ids[i]\n",
    "#             true_id = true_ids[i]\n",
    "#             score = scores[tag]\n",
    "#             print(\"ID=%d\"%ID, \"pred_id=%d\"%pred_id, \"true_id=%d\"%true_id)\n",
    "#             if ID == pred_id:\n",
    "#                 score[\"count_pred\"] = score[\"count_pred\"] + 1\n",
    "#                 if pred_id == true_id:\n",
    "#                     score[\"count_tp\"] = score[\"count_tp\"] + 1\n",
    "#             elif ID == true_id:\n",
    "#                 score[\"count_true\"] = score[\"count_true\"] + 1\n",
    "#                 if pred_id == true_id:\n",
    "#                     score[\"count_tp\"] = score[\"count_tp\"] + 1\n",
    "    return scores\n",
    "\n",
    "scores = caculate_precision_recall_f1(tag2id, id2tag, pred_y_results, true_y_results)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:37:19.983153Z",
     "start_time": "2019-10-31T07:37:19.959985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'tag': 'O',\n",
       "  'id': 0,\n",
       "  'count_tp': 100204,\n",
       "  'count_true': 101469,\n",
       "  'count_pred': 130042,\n",
       "  'precision': 0.7705510527368081,\n",
       "  'recall': 0.9875331381998443,\n",
       "  'f1': 0.8656521720350221},\n",
       " 1: {'tag': 'B-PER',\n",
       "  'id': 1,\n",
       "  'count_tp': 322,\n",
       "  'count_true': 906,\n",
       "  'count_pred': 405,\n",
       "  'precision': 0.7950617283950617,\n",
       "  'recall': 0.3554083885209713,\n",
       "  'f1': 0.49122807017543857},\n",
       " 2: {'tag': 'I-PER',\n",
       "  'id': 2,\n",
       "  'count_tp': 988,\n",
       "  'count_true': 1879,\n",
       "  'count_pred': 1291,\n",
       "  'precision': 0.7652982184353214,\n",
       "  'recall': 0.5258116019159127,\n",
       "  'f1': 0.6233438485804417},\n",
       " 3: {'tag': 'B-LOC',\n",
       "  'id': 3,\n",
       "  'count_tp': 1079,\n",
       "  'count_true': 1726,\n",
       "  'count_pred': 1388,\n",
       "  'precision': 0.7773775216138329,\n",
       "  'recall': 0.6251448435689455,\n",
       "  'f1': 0.692999357739242},\n",
       " 4: {'tag': 'I-LOC',\n",
       "  'id': 4,\n",
       "  'count_tp': 1529,\n",
       "  'count_true': 2652,\n",
       "  'count_pred': 2237,\n",
       "  'precision': 0.683504693786321,\n",
       "  'recall': 0.5765460030165912,\n",
       "  'f1': 0.6254857844139906},\n",
       " 5: {'tag': 'B-ORG',\n",
       "  'id': 5,\n",
       "  'count_tp': 223,\n",
       "  'count_true': 599,\n",
       "  'count_pred': 397,\n",
       "  'precision': 0.5617128463476071,\n",
       "  'recall': 0.3722871452420701,\n",
       "  'f1': 0.4477911646586345},\n",
       " 6: {'tag': 'I-ORG',\n",
       "  'id': 6,\n",
       "  'count_tp': 1893,\n",
       "  'count_true': 2825,\n",
       "  'count_pred': 3170,\n",
       "  'precision': 0.5971608832807571,\n",
       "  'recall': 0.6700884955752212,\n",
       "  'f1': 0.6315262718932444}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(scores)\n",
    "def get_results(scores):\n",
    "    count_tp_total = 0\n",
    "    for k in scores.keys():\n",
    "        score = scores[k]\n",
    "        count_tp_total += score[\"count_tp\"]\n",
    "        score[\"precision\"] = score[\"count_tp\"] / score[\"count_pred\"]\n",
    "        score[\"recall\"] = score[\"count_tp\"] / score[\"count_true\"]\n",
    "        score[\"f1\"] =  2 * score[\"precision\"] * score[\"recall\"] / (score[\"precision\"] + score[\"recall\"])\n",
    "#     score[\"total\"] = {\n",
    "#         \"accuracy\" : count_tp_total / total_num\n",
    "#     }\n",
    "    return scores\n",
    "results = get_results(scores)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:37:23.621722Z",
     "start_time": "2019-10-31T07:37:23.616686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Wrapper\n",
    "from keras.layers import Bidirectional\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T08:11:30.965850Z",
     "start_time": "2019-10-31T08:11:28.901746Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print------- <keras.engine.training.Model object at 0x153134a58>\n",
      "- <keras.engine.input_layer.InputLayer object at 0x1516626d8> False\n",
      "- <keras.layers.embeddings.Embedding object at 0x1516628d0> False\n",
      "- <keras.layers.wrappers.Bidirectional object at 0x152eec400> False\n",
      "- <keras.layers.recurrent.LSTM object at 0x152eec080> False\n",
      "- <keras.layers.recurrent.LSTM object at 0x152eec550> False\n",
      "- <keras_contrib.layers.crf.CRF object at 0x152eec7b8> True\n",
      "freeze------ <keras.engine.input_layer.InputLayer object at 0x1516626d8>\n",
      "freeze------ <keras.layers.embeddings.Embedding object at 0x1516628d0>\n",
      "freeze------ <keras.layers.wrappers.Bidirectional object at 0x152eec400>\n",
      "-wrapper <keras.layers.wrappers.Bidirectional object at 0x152eec400>\n",
      "freeze------ <keras_contrib.layers.crf.CRF object at 0x163920f98>\n",
      "-layer_crf <keras_contrib.layers.crf.CRF object at 0x163920f98> True\n",
      "-layer_crf_output Tensor(\"out_crf_transfer_4/cond/Merge:0\", shape=(?, ?, 13), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_char (InputLayer)      (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embed_char (Embedding)       (None, 30, 50)            253700    \n",
      "_________________________________________________________________\n",
      "bilstm (Bidirectional)       (None, 30, 20)            4880      \n",
      "_________________________________________________________________\n",
      "out_crf_transfer (CRF)       (None, 30, 13)            468       \n",
      "=================================================================\n",
      "Total params: 259,048\n",
      "Trainable params: 468\n",
      "Non-trainable params: 258,580\n",
      "_________________________________________________________________\n",
      "print------- <keras.engine.training.Model object at 0x1638680f0>\n",
      "- <keras.engine.input_layer.InputLayer object at 0x1516626d8> False\n",
      "- <keras.layers.embeddings.Embedding object at 0x1516628d0> False\n",
      "- <keras.layers.wrappers.Bidirectional object at 0x152eec400> False\n",
      "- <keras.layers.recurrent.LSTM object at 0x152eec080> False\n",
      "- <keras.layers.recurrent.LSTM object at 0x152eec550> False\n",
      "- <keras_contrib.layers.crf.CRF object at 0x163920f98> True\n"
     ]
    }
   ],
   "source": [
    "def print_model(model, name):\n",
    "    print(\"print-------\", model)\n",
    "    for layer in model.layers:\n",
    "        print(\"-\", layer, layer.trainable)\n",
    "        if  isinstance(layer, Wrapper):\n",
    "            print(\"-\",layer.forward_layer, layer.forward_layer.trainable)\n",
    "            print(\"-\",layer.backward_layer, layer.backward_layer.trainable)\n",
    "#     plot_model(model)\n",
    "\n",
    "def freeze_layer(layer):\n",
    "    print(\"freeze------\", layer)\n",
    "    layer.trainable = False\n",
    "    #修复keras 2.2.4版本的bug，Wrapper嵌套的layer也需要设置trainable \n",
    "    if  isinstance(layer, Wrapper):\n",
    "        print (\"-wrapper\", layer)\n",
    "        layer.forward_layer.trainable = False\n",
    "        layer.backward_layer.trainable = False\n",
    "    if hasattr(layer, \"layers\"):\n",
    "        for l in layer.layers:\n",
    "            freez_layer(l)\n",
    "            \n",
    "def freeze_model(model):      \n",
    "    for layer in model.layers:\n",
    "        freeze_layer(layer)\n",
    "\n",
    "def create_transfer_model(base_model : Model, tags_num):\n",
    "    print_model(base_model, \"base_model\")\n",
    "    layer_input = base_model.inputs\n",
    "    layer_lstm = base_model.layers[-2]\n",
    "    base_model.trainable = True\n",
    "    layer_crf = CRF(units = tags_num, sparse_target = True, name=\"out_crf_transfer\")\n",
    "    layer_crf_output = layer_crf(layer_lstm.output)\n",
    "    model = Model(inputs = layer_input, outputs = [layer_crf_output])\n",
    "    \n",
    "    freeze_model(model)\n",
    "    layer_crf.trainable = True\n",
    "    print(\"-layer_crf\", layer_crf, layer_crf.trainable)\n",
    "    print(\"-layer_crf_output\", layer_crf_output)\n",
    "#     model.layers[-1].trainable = True\n",
    "#     print(\"-model.layer[-1]\", model.layers[-1])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss = crf_loss,\n",
    "                  metrics= [crf_accuracy]\n",
    "                 )                                                                                    \n",
    "    model.summary() \n",
    "    \n",
    "    print_model(model, \"transfer_model\")\n",
    "    return model\n",
    "\n",
    "transfer_model = create_transfer_model(normal_model, transfer_tags_num)\n",
    "\n",
    "transfer_model.save(\"transfer_model.h5\")\n",
    "# normal_model.save(\"normal_model_transfered.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T07:39:39.148375Z",
     "start_time": "2019-10-31T07:39:00.849880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9445 samples, validate on 1036 samples\n",
      "Epoch 1/5\n",
      "9445/9445 [==============================] - 9s 922us/step - loss: 2.8994 - crf_accuracy: 0.7235 - val_loss: 2.0867 - val_crf_accuracy: 0.8737\n",
      "Epoch 2/5\n",
      "9445/9445 [==============================] - 7s 757us/step - loss: 2.3377 - crf_accuracy: 0.8766 - val_loss: 1.9979 - val_crf_accuracy: 0.8738\n",
      "Epoch 3/5\n",
      "9445/9445 [==============================] - 7s 760us/step - loss: 2.2724 - crf_accuracy: 0.8771 - val_loss: 1.9392 - val_crf_accuracy: 0.8745\n",
      "Epoch 4/5\n",
      "9445/9445 [==============================] - 7s 779us/step - loss: 2.2226 - crf_accuracy: 0.8808 - val_loss: 1.8917 - val_crf_accuracy: 0.8771\n",
      "Epoch 5/5\n",
      "9445/9445 [==============================] - 7s 772us/step - loss: 2.1832 - crf_accuracy: 0.8845 - val_loss: 1.8556 - val_crf_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "transfer_model.fit(transfer_train_X, transfer_train_y, verbose=1, epochs=5, validation_data=(\n",
    "    transfer_test_X, transfer_test_y\n",
    "))\n",
    "\n",
    "transfer_model.save(\"transfer_model_fited.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "253px",
    "left": "1025px",
    "right": "20px",
    "top": "120px",
    "width": "375px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
